import streamlit as st
import pandas as pd
import requests
import xml.etree.ElementTree as ET
import urllib.parse
import feedparser
from datetime import datetime
from dateutil.relativedelta import relativedelta
import time
import os
from difflib import get_close_matches
import re

# -----------------------------------------------------------------------------
# 1. í™”ë©´ ë””ìì¸ ë° ì„¤ì •
# -----------------------------------------------------------------------------
st.set_page_config(
    page_title="ê°•ì›ë„ ë¶€ë™ì‚° í†µí•© ê´€ì œ", 
    page_icon="ğŸ”ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
    <style>
        [data-testid="stSidebar"] { min-width: 400px !important; max-width: 400px !important; }
        .news-box {
            background-color: #262730; padding: 18px; border-radius: 10px;
            margin-bottom: 12px; border-left: 5px solid #03C75A; border: 1px solid #363945;
        }
        .news-title { font-size: 17px; font-weight: bold; color: #ffffff !important; text-decoration: none; display: block; margin-bottom: 5px; }
        .news-title:hover { color: #03C75A !important; text-decoration: underline; }
        .news-meta { font-size: 13px; color: #a0a0a0; }
        .badge-today { background-color: #ff4b4b; color: white; padding: 2px 6px; border-radius: 4px; font-size: 11px; font-weight: bold; margin-right: 8px; }
        .highlight-row { background-color: #ff4b4b20 !important; }
        a { color: #03C75A !important; text-decoration: none; }
    </style>
""", unsafe_allow_html=True)

CSV_FILE = "my_apts.csv"

# â˜… ì§€ì—­ë³„ ì„¤ì • (ì›ì£¼ ê¹”ë”í•˜ê²Œ ì •ë¦¬ ì™„ë£Œ)
REGIONS = {
    "ì¶˜ì²œì‹œ": {
        "code": "51110",
        "dongs": sorted(["í‡´ê³„ë™", "ì˜¨ì˜ë™", "ì„ì‚¬ë™", "í›„í‰ë™", "ë™ë©´", "ì‹ ë¶ì", "ìš°ë‘ë™", "íš¨ìë™", "ê·¼í™”ë™", "ì†Œì–‘ë¡œ", "ì•½ì‚¬ëª…ë™", "ì¹ ì „ë™", "ì‚¬ë†ë™"]),
        "publishers": [
            {"name": "ì „ì²´", "domain_key": "ALL"},
            {"name": "ê°•ì›ì¼ë³´", "domain_key": "kwnews"},
            {"name": "ê°•ì›ë„ë¯¼ì¼ë³´", "domain_key": "kado"},
            {"name": "MSíˆ¬ë°ì´", "domain_key": "mstoday"}
        ]
    },
    "ì›ì£¼ì‹œ": {
        "code": "51130",
        "dongs": sorted(["ë°˜ê³¡ë™", "ë¬´ì‹¤ë™", "ë‹¨êµ¬ë™", "ë‹¨ê³„ë™", "ê´€ì„¤ë™", "ì§€ì •ë©´", "ë¬¸ë§‰ì", "íƒœì¥ë™", "ìš°ì‚°ë™", "ëª…ë¥œë™", "ê°œìš´ë™", "ì¤‘ì•™ë™", "ë´‰ì‚°ë™", "í–‰êµ¬ë™"]),
        "publishers": [
            {"name": "ì „ì²´", "domain_key": "ALL"},
            {"name": "ê°•ì›ì¼ë³´", "domain_key": "kwnews"},
            {"name": "ê°•ì›ë„ë¯¼ì¼ë³´", "domain_key": "kado"}
        ]
    }
}

# -----------------------------------------------------------------------------
# 2. ë°ì´í„° ê´€ë¦¬ í•¨ìˆ˜
# -----------------------------------------------------------------------------
def load_my_apts():
    if not os.path.exists(CSV_FILE):
        df = pd.DataFrame({
            "ì§€ì—­": ["ì¶˜ì²œì‹œ", "ì›ì£¼ì‹œ"],
            "ë™": ["í‡´ê³„ë™", "ë°˜ê³¡ë™"], 
            "ì•„íŒŒíŠ¸ëª…": ["eí¸í•œì„¸ìƒì¶˜ì²œí•œìˆ²ì‹œí‹°", "ì›ì£¼í˜ì‹ ë„ì‹œì¤‘í¥S-í´ë˜ìŠ¤í”„ë¼ë””ì›€"]
        })
        df.to_csv(CSV_FILE, index=False, encoding='utf-8-sig')
        return df
    try: 
        df = pd.read_csv(CSV_FILE)
        if "ì§€ì—­" not in df.columns: df["ì§€ì—­"] = "ì¶˜ì²œì‹œ"
        return df
    except: return pd.DataFrame(columns=["ì§€ì—­", "ë™", "ì•„íŒŒíŠ¸ëª…"])

def save_my_apts(df):
    df.to_csv(CSV_FILE, index=False, encoding='utf-8-sig')

# -----------------------------------------------------------------------------
# 3. ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜
# -----------------------------------------------------------------------------
def get_recent_months(months=6):
    now = datetime.now()
    return [(now - relativedelta(months=i)).strftime("%Y%m") for i in range(months)]

@st.cache_data(ttl=60)
def get_apt_data_api(api_key, region_code):
    if not api_key: return []
    months = get_recent_months(6)
    all_data = []
    base_url = "https://apis.data.go.kr/1613000/RTMSDataSvcAptTradeDev/getRTMSDataSvcAptTradeDev"
    
    for ym in months:
        query_url = f"{base_url}?serviceKey={api_key}&LAWD_CD={region_code}&DEAL_YMD={ym}&numOfRows=1000&pageNo=1"
        try:
            response = requests.get(query_url, timeout=10, verify=False)
            try:
                root = ET.fromstring(response.content)
                if root.findtext('.//resultCode') not in ['00', '000']: continue
                for item in root.findall('.//item'):
                    try:
                        price = int(item.findtext('dealAmount').strip().replace(',', ''))
                        all_data.append({
                            'ê³„ì•½ì¼': f"{item.findtext('dealYear')}-{item.findtext('dealMonth').zfill(2)}-{item.findtext('dealDay').zfill(2)}",
                            'ë™': item.findtext('umdNm').strip(),
                            'ì•„íŒŒíŠ¸ëª…': item.findtext('aptNm').strip(),
                            'ë©´ì ': float(item.findtext('excluUseAr')),
                            'êµ­í† ë¶€ ì‹¤ê±°ë˜ê°€': price,
                        })
                    except: continue
            except: continue
        except: continue
    return all_data

@st.cache_data(ttl=60)
def get_land_data_api(api_key, region_code):
    if not api_key: return []
    months = get_recent_months(6)
    all_data = []
    base_url = "https://apis.data.go.kr/1613000/RTMSDataSvcLandTrade/getRTMSDataSvcLandTrade"
    
    for ym in months:
        query_url = f"{base_url}?serviceKey={api_key}&LAWD_CD={region_code}&DEAL_YMD={ym}&numOfRows=1000&pageNo=1"
        try:
            response = requests.get(query_url, timeout=10, verify=False)
            try:
                root = ET.fromstring(response.content)
                if root.findtext('.//resultCode') not in ['00', '000']: continue
                for item in root.findall('.//item'):
                    try:
                        price = int(item.findtext('dealAmount').strip().replace(',', ''))
                        all_data.append({
                            'ê³„ì•½ì¼': f"{item.findtext('dealYear')}-{item.findtext('dealMonth').zfill(2)}-{item.findtext('dealDay').zfill(2)}",
                            'ë™': item.findtext('umdNm').strip(),
                            'ì•„íŒŒíŠ¸ëª…': item.findtext('jimok'), 
                            'ë©´ì ': float(item.findtext('dealArea')),
                            'êµ­í† ë¶€ ì‹¤ê±°ë˜ê°€': price,
                        })
                    except: continue
            except: continue
        except: continue
    return all_data

# -----------------------------------------------------------------------------
# 4. ìœ í‹¸ë¦¬í‹°
# -----------------------------------------------------------------------------
def get_links(region_name, dong, name, is_land=False):
    city = region_name[:2]
    q = f"{city} {dong} {name}"
    enc = urllib.parse.quote(q)
    if is_land: return {"kb": f"https://map.naver.com/p/search/{enc}", "naver": f"https://new.land.naver.com/search?sk={enc}"}
    return {"kb": f"https://kbland.kr/search?q={enc}", "naver": f"https://new.land.naver.com/search?sk={enc}"}

def get_interest_data(api_list, my_df, current_region):
    if not api_list: return pd.DataFrame()
    df_api = pd.DataFrame(api_list)
    region_df = my_df[my_df['ì§€ì—­'] == current_region]
    my_interests = set(zip(region_df['ë™'], region_df['ì•„íŒŒíŠ¸ëª…']))
    df_interest = df_api[df_api.apply(lambda x: (x['ë™'], x['ì•„íŒŒíŠ¸ëª…']) in my_interests, axis=1)].copy()
    
    found_interests = set(zip(df_interest['ë™'], df_interest['ì•„íŒŒíŠ¸ëª…'])) if not df_interest.empty else set()
    dummy_rows = []
    for _, row in region_df.iterrows():
        if (row['ë™'], row['ì•„íŒŒíŠ¸ëª…']) not in found_interests:
            dummy_rows.append({
                'ê³„ì•½ì¼': '-', 'ë™': row['ë™'], 'ì•„íŒŒíŠ¸ëª…': row['ì•„íŒŒíŠ¸ëª…'], 
                'ë©´ì ': None, 'êµ­í† ë¶€ ì‹¤ê±°ë˜ê°€': None 
            })
    
    df_final = pd.concat([df_interest, pd.DataFrame(dummy_rows)], ignore_index=True)
    if df_final.empty: return pd.DataFrame()
    
    df_final['sort_date'] = df_final['ê³„ì•½ì¼'].apply(lambda x: '9999-99-99' if x == '-' else x)
    return df_final.sort_values(by=['sort_date', 'ë™'], ascending=[False, True]).drop(columns=['sort_date'])

def get_inferred_apt_name(api_data, input_name, input_dong):
    if not api_data or not input_name: return input_name
    dong_apts = list(set([d['ì•„íŒŒíŠ¸ëª…'] for d in api_data if d['ë™'] == input_dong]))
    matches = get_close_matches(input_name, dong_apts, n=1, cutoff=0.2)
    return matches[0] if matches else input_name

# -----------------------------------------------------------------------------
# 5. ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘
# -----------------------------------------------------------------------------
def clean_html(text):
    return re.sub('<.+?>', '', text).replace('&quot;', '"').replace('&apos;', "'").replace('&amp;', '&')

def get_naver_news_list(client_id, client_secret, region_name, category, publisher_name, domain_key):
    if not client_id or not client_secret: return []
    city = region_name[:2]
    search_keyword = f"{city} ë¶€ë™ì‚°" if category == "ë¶€ë™ì‚°" else city
    if publisher_name != "ì „ì²´": search_keyword += f" {publisher_name}"
        
    url = "https://openapi.naver.com/v1/search/news.json"
    headers = {"X-Naver-Client-Id": client_id, "X-Naver-Client-Secret": client_secret}
    params = {"query": search_keyword, "display": 100 if publisher_name != "ì „ì²´" else 20, "start": 1, "sort": "date"}
    
    try:
        res = requests.get(url, headers=headers, params=params, timeout=5)
        if res.status_code == 200:
            items = res.json().get('items', [])
            news = []
            today = datetime.now().strftime("%Y-%m-%d")
            for item in items:
                link = item['link']
                originallink = item.get('originallink', '')
                if domain_key != "ALL":
                    if (domain_key not in link) and (domain_key not in originallink): continue
                try:
                    pub_date = datetime.strptime(item['pubDate'], "%a, %d %b %Y %H:%M:%S +0900")
                    date_str = pub_date.strftime("%Y-%m-%d")
                except: date_str = item['pubDate']
                
                news.append({
                    'title': clean_html(item['title']),
                    'link': originallink if originallink else link,
                    'date_str': date_str,
                    'is_today': date_str == today,
                    'source': publisher_name
                })
            return news[:20]
        return []
    except: return []

# -----------------------------------------------------------------------------
# 6. ë©”ì¸ UI (ë°°í¬ìš© Secrets ìë™ ë¡œë“œ ì ìš©)
# -----------------------------------------------------------------------------
st.title("ğŸ”ï¸ ê°•ì›ë„ ë¶€ë™ì‚° í†µí•© ê´€ì œ ì‹œìŠ¤í…œ")

# [ë°°í¬ìš©] Secrets ìë™ ë¡œë“œ ë¡œì§
# st.secretsì— í‚¤ê°€ ìˆìœ¼ë©´ ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ ì‚¬ì´ë“œë°” ì…ë ¥ì°½ì„ ë„ì›€
with st.sidebar:
    st.header("ğŸ”‘ API ì„¤ì •")
    
    # 1. ê³µê³µë°ì´í„° ì¸ì¦í‚¤
    if "public_api_key" in st.secrets:
        api_key_val = st.secrets["public_api_key"]
        st.success("âœ… ê³µê³µë°ì´í„° í‚¤ ìë™ ì—°ê²°ë¨")
    else:
        api_key_val = st.text_input("ê³µê³µë°ì´í„° ì¸ì¦í‚¤(Decoding)", type="password", help="secrets.tomlì— 'public_api_key'ë¡œ ì €ì¥í•˜ë©´ ìë™ ë¡œë“œë©ë‹ˆë‹¤.")
    
    st.divider()
    
    # 2. ë„¤ì´ë²„ API í‚¤
    if "naver_client_id" in st.secrets and "naver_client_secret" in st.secrets:
        naver_id = st.secrets["naver_client_id"]
        naver_secret = st.secrets["naver_client_secret"]
        st.success("âœ… ë„¤ì´ë²„ ê²€ìƒ‰ í‚¤ ìë™ ì—°ê²°ë¨")
    else:
        st.caption("ë‰´ìŠ¤ ê²€ìƒ‰ìš© ë„¤ì´ë²„ í‚¤")
        naver_id = st.text_input("Naver Client ID", type="password")
        naver_secret = st.text_input("Naver Client Secret", type="password")
    
    st.divider()

region_tabs = st.tabs(["ì¶˜ì²œì‹œ", "ì›ì£¼ì‹œ"])

common_config = {
    "kb_link": st.column_config.LinkColumn("KB", display_text="í™•ì¸í•˜ê¸°"),
    "naver_link": st.column_config.LinkColumn("ë„¤ì´ë²„", display_text="í™•ì¸í•˜ê¸°"),
    "ë©´ì ": st.column_config.NumberColumn(format="%.2f mÂ²"),
    "êµ­í† ë¶€ ì‹¤ê±°ë˜ê°€": st.column_config.NumberColumn(label="êµ­í† ë¶€ ì‹¤ê±°ë˜ê°€ (ë§Œì›)", format="%,d"),
}

def render_region_dashboard(region_name):
    r_code = REGIONS[region_name]["code"]
    r_dongs = REGIONS[region_name]["dongs"]
    r_pubs = REGIONS[region_name]["publishers"]
    
    raw_for_infer = []
    if api_key_val:
        raw_for_infer = get_apt_data_api(api_key_val, r_code)

    with st.sidebar:
        with st.expander(f"ğŸ“Œ {region_name} ê´€ì‹¬ ì•„íŒŒíŠ¸ ê´€ë¦¬", expanded=True):
            with st.form(f"add_apt_{region_name}", clear_on_submit=True):
                c1, c2 = st.columns(2)
                input_dong = c1.selectbox("ë™ ì„ íƒ", r_dongs)
                input_name = c2.text_input("ì•„íŒŒíŠ¸ëª…")
                if st.form_submit_button("ì¶”ê°€"):
                    if input_name:
                        full_name = get_inferred_apt_name(raw_for_infer, input_name, input_dong)
                        if full_name != input_name: st.toast(f"ğŸ’¡ '{full_name}' ë³´ì •ë¨")
                        curr_df = load_my_apts()
                        cond = (curr_df['ì§€ì—­'] == region_name) & (curr_df['ë™'] == input_dong) & (curr_df['ì•„íŒŒíŠ¸ëª…'] == full_name)
                        if not cond.any():
                            new_entry = pd.DataFrame({"ì§€ì—­": [region_name], "ë™": [input_dong], "ì•„íŒŒíŠ¸ëª…": [full_name]})
                            save_my_apts(pd.concat([curr_df, new_entry], ignore_index=True))
                            st.rerun()

            st.caption(f"ğŸ“‹ {region_name} ê´€ë¦¬ ëª©ë¡")
            my_df = load_my_apts()
            region_my_df = my_df[my_df['ì§€ì—­'] == region_name]
            for idx, row in region_my_df.iterrows():
                rc1, rc2 = st.columns([0.8, 0.2])
                rc1.text(f"[{row['ë™']}] {row['ì•„íŒŒíŠ¸ëª…']}")
                if rc2.button("ì‚­ì œ", key=f"del_{region_name}_{idx}"):
                    save_my_apts(my_df.drop(idx))
                    st.rerun()

    st.markdown(f"### ğŸ” {region_name} ì‹¤ê±°ë˜ í˜„í™©")
    
    t1, t2, t3 = st.tabs(["ğŸ¢ ì•„íŒŒíŠ¸", "â›°ï¸ í† ì§€", "ğŸ“° ì§€ì—­ ë‰´ìŠ¤"])

    with t1:
        if api_key_val:
            sub_t1, sub_t2 = st.tabs(["â™¥ ê´€ì‹¬ ë§¤ë¬¼", "ğŸ“‹ ì „ì²´ ì‹¤ê±°ë˜"])
            with sub_t1:
                df_interest = get_interest_data(raw_for_infer, my_df, region_name)
                if not df_interest.empty:
                    df_interest['kb_link'] = df_interest.apply(lambda x: get_links(region_name, x['ë™'], x['ì•„íŒŒíŠ¸ëª…'])['kb'] if x['ì•„íŒŒíŠ¸ëª…'] != '-' else '-', axis=1)
                    df_interest['naver_link'] = df_interest.apply(lambda x: get_links(region_name, x['ë™'], x['ì•„íŒŒíŠ¸ëª…'])['naver'] if x['ì•„íŒŒíŠ¸ëª…'] != '-' else '-', axis=1)
                    st.dataframe(df_interest, column_config=common_config, column_order=["ê³„ì•½ì¼", "ë™", "ì•„íŒŒíŠ¸ëª…", "ë©´ì ", "êµ­í† ë¶€ ì‹¤ê±°ë˜ê°€", "kb_link", "naver_link"], hide_index=True, use_container_width=True)
                else: st.info("ê´€ì‹¬ ë§¤ë¬¼ ê±°ë˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
            with sub_t2:
                if raw_for_infer:
                    df_all = pd.DataFrame(raw_for_infer).sort_values(by="ê³„ì•½ì¼", ascending=False)
                    df_all['kb_link'] = df_all.apply(lambda x: get_links(region_name, x['ë™'], x['ì•„íŒŒíŠ¸ëª…'])['kb'], axis=1)
                    df_all['naver_link'] = df_all.apply(lambda x: get_links(region_name, x['ë™'], x['ì•„íŒŒíŠ¸ëª…'])['naver'], axis=1)
                    st.dataframe(df_all, column_config=common_config, column_order=["ê³„ì•½ì¼", "ë™", "ì•„íŒŒíŠ¸ëª…", "ë©´ì ", "êµ­í† ë¶€ ì‹¤ê±°ë˜ê°€", "kb_link", "naver_link"], hide_index=True, use_container_width=True)
                else: st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else: st.warning("ê³µê³µë°ì´í„° API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    with t2:
        if api_key_val:
            l_raw = get_land_data_api(api_key_val, r_code)
            sub_l1, sub_l2 = st.tabs(["â™¥ ê´€ì‹¬ ë™ë„¤", "ğŸ“‹ ì „ì²´ ì‹¤ê±°ë˜"])
            land_config = common_config.copy()
            land_config["ì•„íŒŒíŠ¸ëª…"] = st.column_config.TextColumn("ì§€ëª©")

            with sub_l1:
                interest_dongs = my_df[my_df['ì§€ì—­'] == region_name]['ë™'].unique()
                if l_raw:
                    df_l = pd.DataFrame(l_raw)
                    df_l_int = df_l[df_l['ë™'].isin(interest_dongs)].sort_values(by="ê³„ì•½ì¼", ascending=False)
                    if not df_l_int.empty:
                        df_l_int['kb_link'] = df_l_int.apply(lambda x: get_links(region_name, x['ë™'], x['ì•„íŒŒíŠ¸ëª…'], True)['kb'], axis=1)
                        df_l_int['naver_link'] = df_l_int.apply(lambda x: get_links(region_name, x['ë™'], x['ì•„íŒŒíŠ¸ëª…'], True)['naver'], axis=1)
                        st.dataframe(df_l_int, column_config=land_config, column_order=["ê³„ì•½ì¼", "ë™", "ì•„íŒŒíŠ¸ëª…", "ë©´ì ", "êµ­í† ë¶€ ì‹¤ê±°ë˜ê°€", "kb_link", "naver_link"], hide_index=True, use_container_width=True)
                    else: st.info(f"ê´€ì‹¬ ë™ë„¤({', '.join(interest_dongs)})ì˜ í† ì§€ ê±°ë˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else: st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            with sub_l2:
                if l_raw:
                    df_l_all = pd.DataFrame(l_raw).sort_values(by="ê³„ì•½ì¼", ascending=False)
                    df_l_all['kb_link'] = df_l_all.apply(lambda x: get_links(region_name, x['ë™'], x['ì•„íŒŒíŠ¸ëª…'], True)['kb'], axis=1)
                    df_l_all['naver_link'] = df_l_all.apply(lambda x: get_links(region_name, x['ë™'], x['ì•„íŒŒíŠ¸ëª…'], True)['naver'], axis=1)
                    st.dataframe(df_l_all, column_config=land_config, column_order=["ê³„ì•½ì¼", "ë™", "ì•„íŒŒíŠ¸ëª…", "ë©´ì ", "êµ­í† ë¶€ ì‹¤ê±°ë˜ê°€", "kb_link", "naver_link"], hide_index=True, use_container_width=True)
                else: st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else: st.warning("ê³µê³µë°ì´í„° API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    with t3:
        st.subheader(f"ğŸ“° {region_name} ì£¼ìš” ì†Œì‹")
        
        if not naver_id or not naver_secret:
            st.warning("ë„¤ì´ë²„ API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            nt1, nt2 = st.tabs(["ğŸ  ë¶€ë™ì‚°", "ğŸ“‘ ì¼ë°˜/í†µí•©"])
            def create_news_tabs(cat_name):
                tabs = st.tabs([p['name'] for p in r_pubs])
                for i, tab in enumerate(tabs):
                    with tab:
                        pub_info = r_pubs[i]
                        items = get_naver_news_list(naver_id, naver_secret, region_name, cat_name, pub_info['name'], pub_info['domain_key'])
                        if items:
                            for n in items:
                                b = '<span class="badge-today">ì˜¤ëŠ˜</span>' if n['is_today'] else ''
                                st.markdown(f'<div class="news-box"><a href="{n["link"]}" target="_blank" class="news-title">{b}{n["title"]}</a><div class="news-meta">{n["source"]} | {n["date_str"]}</div></div>', unsafe_allow_html=True)
                        else: st.info(f"'{pub_info['name']}' ê´€ë ¨ ìµœì‹  ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            with nt1: create_news_tabs("ë¶€ë™ì‚°")
            with nt2: create_news_tabs("ì „ì²´")

with region_tabs[0]: render_region_dashboard("ì¶˜ì²œì‹œ")
with region_tabs[1]: render_region_dashboard("ì›ì£¼ì‹œ")