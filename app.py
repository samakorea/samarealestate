import streamlit as st
import pandas as pd
import requests
import xml.etree.ElementTree as ET
import urllib.parse
import feedparser
from datetime import datetime
from dateutil.relativedelta import relativedelta
import time
import os
from difflib import get_close_matches
import re
import altair as alt

# -----------------------------------------------------------------------------
# 1. í™”ë©´ ë””ìì¸ ë° ì„¤ì •
# -----------------------------------------------------------------------------
st.set_page_config(
    page_title="ê°•ì›ë„ ë¶€ë™ì‚° í†µí•© ê´€ì œ", 
    page_icon="ğŸ”ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
    <style>
        [data-testid="stSidebar"] { min-width: 400px !important; max-width: 400px !important; }
        .news-box {
            background-color: #262730; padding: 18px; border-radius: 10px;
            margin-bottom: 12px; border-left: 5px solid #03C75A; border: 1px solid #363945;
        }
        .news-title { font-size: 17px; font-weight: bold; color: #ffffff !important; text-decoration: none; display: block; margin-bottom: 5px; }
        .news-title:hover { color: #03C75A !important; text-decoration: underline; }
        .news-meta { font-size: 13px; color: #a0a0a0; }
        .badge-today { background-color: #ff4b4b; color: white; padding: 2px 6px; border-radius: 4px; font-size: 11px; font-weight: bold; margin-right: 8px; }
        .highlight-row { background-color: #ff4b4b20 !important; }
        a { color: #03C75A !important; text-decoration: none; }
    </style>
""", unsafe_allow_html=True)

CSV_FILE = "my_apts.csv"

# â˜… ì§€ì—­ë³„ ì„¤ì •
REGIONS = {
    "ì¶˜ì²œì‹œ": {
        "code": "51110",
        "dongs": sorted(["í‡´ê³„ë™", "ì˜¨ì˜ë™", "ì„ì‚¬ë™", "í›„í‰ë™", "ë™ë©´", "ì‹ ë¶ì", "ìš°ë‘ë™", "íš¨ìë™", "ê·¼í™”ë™", "ì†Œì–‘ë¡œ", "ì•½ì‚¬ëª…ë™", "ì¹ ì „ë™", "ì‚¬ë†ë™"]),
        "publishers": [
            {"name": "ì „ì²´", "domain_key": "ALL"},
            {"name": "ê°•ì›ì¼ë³´", "domain_key": "kwnews"},
            {"name": "ê°•ì›ë„ë¯¼ì¼ë³´", "domain_key": "kado"},
            {"name": "MSíˆ¬ë°ì´", "domain_key": "mstoday"}
        ]
    },
    "ì›ì£¼ì‹œ": {
        "code": "51130",
        "dongs": sorted(["ë°˜ê³¡ë™", "ë¬´ì‹¤ë™", "ë‹¨êµ¬ë™", "ë‹¨ê³„ë™", "ê´€ì„¤ë™", "ì§€ì •ë©´", "ë¬¸ë§‰ì", "íƒœì¥ë™", "ìš°ì‚°ë™", "ëª…ë¥œë™", "ê°œìš´ë™", "ì¤‘ì•™ë™", "ë´‰ì‚°ë™", "í–‰êµ¬ë™"]),
        "publishers": [
            {"name": "ì „ì²´", "domain_key": "ALL"},
            {"name": "ê°•ì›ì¼ë³´", "domain_key": "kwnews"},
            {"name": "ê°•ì›ë„ë¯¼ì¼ë³´", "domain_key": "kado"},
            {"name": "ì›ì£¼MBC", "domain_key": "wjmbc"}
        ]
    }
}

# -----------------------------------------------------------------------------
# 2. ë°ì´í„° ê´€ë¦¬ í•¨ìˆ˜
# -----------------------------------------------------------------------------
def load_my_apts():
    if not os.path.exists(CSV_FILE):
        df = pd.DataFrame({
            "ì§€ì—­": ["ì¶˜ì²œì‹œ", "ì›ì£¼ì‹œ"],
            "ë™": ["í‡´ê³„ë™", "ë°˜ê³¡ë™"], 
            "ì•„íŒŒíŠ¸ëª…": ["eí¸í•œì„¸ìƒì¶˜ì²œí•œìˆ²ì‹œí‹°", "ì›ì£¼í˜ì‹ ë„ì‹œì¤‘í¥S-í´ë˜ìŠ¤í”„ë¼ë””ì›€"]
        })
        df.to_csv(CSV_FILE, index=False, encoding='utf-8-sig')
        return df
    try: 
        df = pd.read_csv(CSV_FILE)
        if "ì§€ì—­" not in df.columns: df["ì§€ì—­"] = "ì¶˜ì²œì‹œ"
        return df
    except: return pd.DataFrame(columns=["ì§€ì—­", "ë™", "ì•„íŒŒíŠ¸ëª…"])

def save_my_apts(df):
    df.to_csv(CSV_FILE, index=False, encoding='utf-8-sig')

# -----------------------------------------------------------------------------
# 3. ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜
# -----------------------------------------------------------------------------
def get_recent_months(months=6):
    now = datetime.now()
    return [(now - relativedelta(months=i)).strftime("%Y%m") for i in range(months)]

@st.cache_data(ttl=60)
def get_apt_data_api(api_key, region_code):
    if not api_key: return []
    months = get_recent_months(6)
    all_data = []
    base_url = "https://apis.data.go.kr/1613000/RTMSDataSvcAptTradeDev/getRTMSDataSvcAptTradeDev"
    
    for ym in months:
        query_url = f"{base_url}?serviceKey={api_key}&LAWD_CD={region_code}&DEAL_YMD={ym}&numOfRows=1000&pageNo=1"
        try:
            response = requests.get(query_url, timeout=10, verify=False)
            try:
                root = ET.fromstring(response.content)
                if root.findtext('.//resultCode') not in ['00', '000']: continue
                for item in root.findall('.//item'):
                    try:
                        price = int(item.findtext('dealAmount').strip().replace(',', ''))
                        # â˜… ë‚ ì§œ í¬ë§· ë³€ê²½: YYYY.MM.DD
                        date_str = f"{item.findtext('dealYear')}.{item.findtext('dealMonth').zfill(2)}.{item.findtext('dealDay').zfill(2)}"
                        
                        all_data.append({
                            'ê³„ì•½ì¼': date_str,
                            'ë™': item.findtext('umdNm').strip(),
                            'ì•„íŒŒíŠ¸ëª…': item.findtext('aptNm').strip(),
                            'ë©´ì ': float(item.findtext('excluUseAr')),
                            'êµ­í† ë¶€ ì‹¤ê±°ë˜ê°€': price,
                        })
                    except: continue
            except: continue
        except: continue
    return all_data

@st.cache_data(ttl=60)
def get_land_data_api(api_key, region_code):
    if not api_key: return []
    months = get_recent_months(6)
    all_data = []
    base_url = "https://apis.data.go.kr/1613000/RTMSDataSvcLandTrade/getRTMSDataSvcLandTrade"
    
    for ym in months:
        query_url = f"{base_url}?serviceKey={api_key}&LAWD_CD={region_code}&DEAL_YMD={ym}&numOfRows=1000&pageNo=1"
        try:
            response = requests.get(query_url, timeout=10, verify=False)
            try:
                root = ET.fromstring(response.content)
                if root.findtext('.//resultCode') not in ['00', '000']: continue
                for item in root.findall('.//item'):
                    try:
                        price = int(item.findtext('dealAmount').strip().replace(',', ''))
                        # â˜… ë‚ ì§œ í¬ë§· ë³€ê²½: YYYY.MM.DD
                        date_str = f"{item.findtext('dealYear')}.{item.findtext('dealMonth').zfill(2)}.{item.findtext('dealDay').zfill(2)}"
                        
                        all_data.append({
                            'ê³„ì•½ì¼': date_str,
                            'ë™': item.findtext('umdNm').strip(),
                            'ì•„íŒŒíŠ¸ëª…': item.findtext('jimok'), 
                            'ë©´ì ': float(item.findtext('dealArea')),
                            'êµ­í† ë¶€ ì‹¤ê±°ë˜ê°€': price,
                        })
                    except: continue
            except: continue
        except: continue
    return all_data

# -----------------------------------------------------------------------------
# 4. ìœ í‹¸ë¦¬í‹° & ê·¸ë˜í”„
# -----------------------------------------------------------------------------
def get_links(region_name, dong, name, is_land=False):
    city = region_name[:2]
    q = f"{city} {dong} {name}"
    enc = urllib.parse.quote(q)
    if is_land: return {"kb": f"https://map.naver.com/p/search/{enc}", "naver": f"https://new.land.naver.com/search?sk={enc}"}
    return {"kb": f"https://kbland.kr/search?q={enc}", "naver": f"https://new.land.naver.com/search?sk={enc}"}

def get_interest_data(api_list, my_df, current_region):
    if not api_list: return pd.DataFrame()
    df_api = pd.DataFrame(api_list)
    region_df = my_df[my_df['ì§€ì—­'] == current_region]
    my_interests = set(zip(region_df['ë™'], region_df['ì•„íŒŒíŠ¸ëª…']))
    df_interest = df_api[df_api.apply(lambda x: (x['ë™'], x['ì•„íŒŒíŠ¸ëª…']) in my_interests, axis=1)].copy()
    
    found_interests = set(zip(df_interest['ë™'], df_interest['ì•„íŒŒíŠ¸ëª…'])) if not df_interest.empty else set()
    dummy_rows = []
    for _, row in region_df.iterrows():
        if (row['ë™'], row['ì•„íŒŒíŠ¸ëª…']) not in found_interests:
            dummy_rows.append({
                'ê³„ì•½ì¼': '-', 'ë™': row['ë™'], 'ì•„íŒŒíŠ¸ëª…': row['ì•„íŒŒíŠ¸ëª…'], 
                'ë©´ì ': None, 'êµ­í† ë¶€ ì‹¤ê±°ë˜ê°€': None 
            })
    df_final = pd.concat([df_interest, pd.DataFrame(dummy_rows)], ignore_index=True)
    if df_final.empty: return pd.DataFrame()
    
    # ì •ë ¬ìš© ë‚ ì§œ í¬ë§·ë„ ì (.)ìœ¼ë¡œ ë³€ê²½
    df_final['sort_date'] = df_final['ê³„ì•½ì¼'].apply(lambda x: '9999.99.99' if x == '-' else x)
    return df_final.sort_values(by=['sort_date', 'ë™'], ascending=[False, True]).drop(columns=['sort_date'])

def get_inferred_apt_name(api_data, input_name, input_dong):
    if not api_data or not input_name: return input_name
    dong_apts = list(set([d['ì•„íŒŒíŠ¸ëª…'] for d in api_data if d['ë™'] == input_dong]))
    matches = get_close_matches(input_name, dong_apts, n=1, cutoff=0.2)
    return matches[0] if matches else input_name

def plot_apt_trend(df_apt):
    if df_apt.empty:
        st.info("ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ê·¸ë˜í”„ë¥¼ ê·¸ë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    df_apt = df_apt.copy()
    # ë‚ ì§œ íŒŒì‹± (ì  êµ¬ë¶„ì ì²˜ë¦¬)
    df_apt['ê³„ì•½ì¼'] = pd.to_datetime(df_apt['ê³„ì•½ì¼'], format='%Y.%m.%d', errors='coerce')
    
    base = alt.Chart(df_apt).encode(
        x=alt.X('ê³„ì•½ì¼:T', title='ê³„ì•½ì¼', axis=alt.Axis(format='%Y.%m.%d')), # ì¶• í¬ë§·ë„ ë³€ê²½
        y=alt.Y('êµ­í† ë¶€ ì‹¤ê±°ë˜ê°€:Q', title='ê±°ë˜ê¸ˆì•¡(ë§Œì›)', scale=alt.Scale(zero=False)),
        tooltip=[alt.Tooltip('ê³„ì•½ì¼', format='%Y.%m.%d'), 'êµ­í† ë¶€ ì‹¤ê±°ë˜ê°€', 'ë©´ì ']
    )
    
    line = base.mark_line(color='#FF4B4B')
    points = base.mark_circle(size=60, color='#FF4B4B')
    
    chart = (line + points).properties(height=300).interactive()
    st.altair_chart(chart, use_container_width=True)

# -----------------------------------------------------------------------------
# 5. ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘
# -----------------------------------------------------------------------------
def clean_html(text):
    return re.sub('<.+?>', '', text).replace('&quot;', '"').replace('&apos;', "'").replace('&amp;', '&')

def get_naver_news_list(client_id, client_secret, region_name, category, publisher_name, domain_key):
    if not client_id or not client_secret: return []
    city = region_name[:2]
    search_keyword = f"{city} ë¶€ë™ì‚°" if category == "ë¶€ë™ì‚°" else city
    if publisher_name != "ì „ì²´": search_keyword += f" {publisher_name}"
        
    url = "https://openapi.naver.com/v1/search/news.json"
    headers = {"X-Naver-Client-Id": client_id, "X-Naver-Client-Secret": client_secret}
    params = {"query": search_keyword, "display": 100 if publisher_name != "ì „ì²´" else 20, "start": 1, "sort": "date"}
    
    try:
        res = requests.get(url, headers=headers, params=params, timeout=5)
        if res.status_code == 200:
            items = res.json().get('items', [])
            news = []
            today = datetime.now().strftime("%Y-%m-%d") # ë¹„êµìš© ì˜¤ëŠ˜ ë‚ ì§œ
            for item in items:
                link = item['link']
                originallink = item.get('originallink', '')
                if domain_key != "ALL":
                    if (domain_key not in link) and (domain_key not in originallink): continue
                try:
                    # ë‰´ìŠ¤ ë‚ ì§œ í¬ë§· ë³€ê²½: YYYY.MM.DD
                    pub_date = datetime.strptime(item['pubDate'], "%a, %d %b %Y %H:%M:%S +0900")
                    date_str = pub_date.strftime("%Y.%m.%d")
                    # ì˜¤ëŠ˜ ë‚ ì§œ ë¹„êµë¥¼ ìœ„í•´ YYYY-MM-DD í¬ë§·ë„ ì ì‹œ ì‚¬ìš©
                    compare_date = pub_date.strftime("%Y-%m-%d")
                except: 
                    date_str = item['pubDate']
                    compare_date = date_str
                
                news.append({
                    'title': clean_html(item['title']),
                    'link': originallink if originallink else link,
                    'date_str': date_str,
                    'is_today': compare_date == today,
                    'source': publisher_name
                })
            return news[:20]
        return []
    except: return []

# -----------------------------------------------------------------------------
# 6. ë©”ì¸ UI
# -----------------------------------------------------------------------------
st.title("ğŸ”ï¸ ê°•ì›ë„ ë¶€ë™ì‚° í†µí•© ê´€ì œ ì‹œìŠ¤í…œ")

with st.sidebar:
    st.header("ğŸ”‘ API ì„¤ì •")
    if "public_api_key" in st.secrets:
        api_key_val = st.secrets["public_api_key"]
        st.success("âœ… ê³µê³µë°ì´í„° í‚¤ ìë™ ì—°ê²°ë¨")
    else:
        api_key_val = st.text_input("ê³µê³µë°ì´í„° ì¸ì¦í‚¤(Decoding)", type="password")
    
    st.divider()
    
    if "naver_client_id" in st.secrets and "naver_client_secret" in st.secrets:
        naver_id = st.secrets["naver_client_id"]
        naver_secret = st.secrets["naver_client_secret"]
        st.success("âœ… ë„¤ì´ë²„ ê²€ìƒ‰ í‚¤ ìë™ ì—°ê²°ë¨")
    else:
        st.caption("ë‰´ìŠ¤ ê²€ìƒ‰ìš© ë„¤ì´ë²„ í‚¤")
        naver_id = st.text_input("Naver Client ID", type="password")
        naver_secret = st.text_input("Naver Client Secret", type="password")
    
    st.divider()

region_tabs = st.tabs(["ì¶˜ì²œì‹œ", "ì›ì£¼ì‹œ"])

common_config = {
    "kb_link": st.column_config.LinkColumn("KB", display_text="í™•ì¸í•˜ê¸°"),
    "naver_link": st.column_config.LinkColumn("ë„¤ì´ë²„", display_text="í™•ì¸í•˜ê¸°"),
    "ë©´ì ": st.column_config.NumberColumn(format="%.2f mÂ²"),
    "êµ­í† ë¶€ ì‹¤ê±°ë˜ê°€": st.column_config.NumberColumn(label="êµ­í† ë¶€ ì‹¤ê±°ë˜ê°€ (ë§Œì›)", format="%,d"),
}

def render_region_dashboard(region_name):
    r_code = REGIONS[region_name]["code"]
    r_dongs = REGIONS[region_name]["dongs"]
    r_pubs = REGIONS[region_name]["publishers"]
    
    raw_data = []
    if api_key_val:
        raw_data = get_apt_data_api(api_key_val, r_code)

    # --- ì‚¬ì´ë“œë°” (ê´€ì‹¬ ê´€ë¦¬) ---
    with st.sidebar:
        with st.expander(f"ğŸ“Œ {region_name} ê´€ì‹¬ ì•„íŒŒíŠ¸ ê´€ë¦¬", expanded=True):
            with st.form(f"add_apt_{region_name}", clear_on_submit=True):
                c1, c2 = st.columns(2)
                input_dong = c1.selectbox("ë™ ì„ íƒ", r_dongs)
                input_name = c2.text_input("ì•„íŒŒíŠ¸ëª…")
                if st.form_submit_button("ì¶”ê°€"):
                    if input_name:
                        full_name = get_inferred_apt_name(raw_data, input_name, input_dong)
                        if full_name != input_name: st.toast(f"ğŸ’¡ '{full_name}' ë³´ì •ë¨")
                        curr_df = load_my_apts()
                        cond = (curr_df['ì§€ì—­'] == region_name) & (curr_df['ë™'] == input_dong) & (curr_df['ì•„íŒŒíŠ¸ëª…'] == full_name)
                        if not cond.any():
                            new_entry = pd.DataFrame({"ì§€ì—­": [region_name], "ë™": [input_dong], "ì•„íŒŒíŠ¸ëª…": [full_name]})
                            save_my_apts(pd.concat([curr_df, new_entry], ignore_index=True))
                            st.rerun()

            st.caption(f"ğŸ“‹ {region_name} ê´€ë¦¬ ëª©ë¡")
            my_df = load_my_apts()
            region_my_df = my_df[my_df['ì§€ì—­'] == region_name]
            for idx, row in region_my_df.iterrows():
                rc1, rc2 = st.columns([0.8, 0.2])
                rc1.text(f"[{row['ë™']}] {row['ì•„íŒŒíŠ¸ëª…']}")
                if rc2.button("ì‚­ì œ", key=f"del_{region_name}_{idx}"):
                    save_my_apts(my_df.drop(idx))
                    st.rerun()

    st.markdown(f"### ğŸ” {region_name} ì‹¤ê±°ë˜ í˜„í™©")
    
    t1, t2, t3 = st.tabs(["ğŸ¢ ì•„íŒŒíŠ¸", "â›°ï¸ í† ì§€", "ğŸ“° ì§€ì—­ ë‰´ìŠ¤"])

    # 1. ì•„íŒŒíŠ¸ íƒ­
    with t1:
        if api_key_val and raw_data:
            df_all = pd.DataFrame(raw_data).sort_values(by="ê³„ì•½ì¼", ascending=False)
            
            st.markdown("#### ğŸ“‰ ì•„íŒŒíŠ¸ ì‹œì„¸ ì§‘ì¤‘ ë¶„ì„")
            col_sel1, col_sel2 = st.columns(2)
            
            available_dongs = sorted(df_all['ë™'].unique())
            selected_dong = col_sel1.selectbox(f"ë™ ì„ íƒ ({region_name})", available_dongs)
            
            available_apts = sorted(df_all[df_all['ë™'] == selected_dong]['ì•„íŒŒíŠ¸ëª…'].unique())
            selected_apt = col_sel2.selectbox(f"ì•„íŒŒíŠ¸ ì„ íƒ ({region_name})", available_apts)
            
            if selected_apt:
                target_df = df_all[(df_all['ë™'] == selected_dong) & (df_all['ì•„íŒŒíŠ¸ëª…'] == selected_apt)].sort_values(by="ê³„ì•½ì¼")
                
                if not target_df.empty:
                    max_price = target_df['êµ­í† ë¶€ ì‹¤ê±°ë˜ê°€'].max()
                    avg_price = target_df['êµ­í† ë¶€ ì‹¤ê±°ë˜ê°€'].mean()
                    recent_price = target_df.iloc[-1]['êµ­í† ë¶€ ì‹¤ê±°ë˜ê°€']
                    
                    m1, m2, m3 = st.columns(3)
                    m1.metric("ìµœê³  ì‹¤ê±°ë˜ê°€", f"{max_price:,} ë§Œì›")
                    m2.metric("ê¸°ê°„ ë‚´ í‰ê· ê°€", f"{int(avg_price):,} ë§Œì›")
                    m3.metric("ìµœê·¼ ê±°ë˜ê°€", f"{recent_price:,} ë§Œì›", delta_color="off")
                    
                    st.caption(f"ğŸ“Š {selected_apt} ìµœê·¼ ê±°ë˜ ì¶”ì´")
                    plot_apt_trend(target_df)
                else:
                    st.warning("í•´ë‹¹ ì•„íŒŒíŠ¸ì˜ ìµœê·¼ ê±°ë˜ ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
            
            st.divider()

            sub_t1, sub_t2 = st.tabs(["â™¥ ê´€ì‹¬ ë§¤ë¬¼ ëª¨ì•„ë³´ê¸°", "ğŸ“‹ ì „ì²´ ì‹¤ê±°ë˜ ë‚´ì—­"])
            
            with sub_t1:
                df_interest = get_interest_data(raw_data, my_df, region_name)
                if not df_interest.empty:
                    df_interest['kb_link'] = df_interest.apply(lambda x: get_links(region_name, x['ë™'], x['ì•„íŒŒíŠ¸ëª…'])['kb'] if x['ì•„íŒŒíŠ¸ëª…'] != '-' else '-', axis=1)
                    df_interest['naver_link'] = df_interest.apply(lambda x: get_links(region_name, x['ë™'], x['ì•„íŒŒíŠ¸ëª…'])['naver'] if x['ì•„íŒŒíŠ¸ëª…'] != '-' else '-', axis=1)
                    st.dataframe(df_interest, column_config=common_config, column_order=["ê³„ì•½ì¼", "ë™", "ì•„íŒŒíŠ¸ëª…", "ë©´ì ", "êµ­í† ë¶€ ì‹¤ê±°ë˜ê°€", "kb_link", "naver_link"], hide_index=True, use_container_width=True)
                else: st.info("ê´€ì‹¬ ë§¤ë¬¼ ê±°ë˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            with sub_t2:
                df_all['kb_link'] = df_all.apply(lambda x: get_links(region_name, x['ë™'], x['ì•„íŒŒíŠ¸ëª…'])['kb'], axis=1)
                df_all['naver_link'] = df_all.apply(lambda x: get_links(region_name, x['ë™'], x['ì•„íŒŒíŠ¸ëª…'])['naver'], axis=1)
                st.dataframe(df_all, column_config=common_config, column_order=["ê³„ì•½ì¼", "ë™", "ì•„íŒŒíŠ¸ëª…", "ë©´ì ", "êµ­í† ë¶€ ì‹¤ê±°ë˜ê°€", "kb_link", "naver_link"], hide_index=True, use_container_width=True)
        
        elif not api_key_val:
            st.warning("API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            st.info("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì´ê±°ë‚˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # 2. í† ì§€ íƒ­
    with t2:
        if api_key_val:
            l_raw = get_land_data_api(api_key_val, r_code)
            sub_l1, sub_l2 = st.tabs(["â™¥ ê´€ì‹¬ ë™ë„¤", "ğŸ“‹ ì „ì²´ ì‹¤ê±°ë˜"])
            land_config = common_config.copy()
            land_config["ì•„íŒŒíŠ¸ëª…"] = st.column_config.TextColumn("ì§€ëª©")

            with sub_l1:
                interest_dongs = my_df[my_df['ì§€ì—­'] == region_name]['ë™'].unique()
                if l_raw:
                    df_l = pd.DataFrame(l_raw)
                    df_l_int = df_l[df_l['ë™'].isin(interest_dongs)].sort_values(by="ê³„ì•½ì¼", ascending=False)
                    if not df_l_int.empty:
                        df_l_int['kb_link'] = df_l_int.apply(lambda x: get_links(region_name, x['ë™'], x['ì•„íŒŒíŠ¸ëª…'], True)['kb'], axis=1)
                        df_l_int['naver_link'] = df_l_int.apply(lambda x: get_links(region_name, x['ë™'], x['ì•„íŒŒíŠ¸ëª…'], True)['naver'], axis=1)
                        st.dataframe(df_l_int, column_config=land_config, column_order=["ê³„ì•½ì¼", "ë™", "ì•„íŒŒíŠ¸ëª…", "ë©´ì ", "êµ­í† ë¶€ ì‹¤ê±°ë˜ê°€", "kb_link", "naver_link"], hide_index=True, use_container_width=True)
                    else: st.info(f"ê´€ì‹¬ ë™ë„¤({', '.join(interest_dongs)})ì˜ í† ì§€ ê±°ë˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else: st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            with sub_l2:
                if l_raw:
                    df_l_all = pd.DataFrame(l_raw).sort_values(by="ê³„ì•½ì¼", ascending=False)
                    df_l_all['kb_link'] = df_l_all.apply(lambda x: get_links(region_name, x['ë™'], x['ì•„íŒŒíŠ¸ëª…'], True)['kb'], axis=1)
                    df_l_all['naver_link'] = df_l_all.apply(lambda x: get_links(region_name, x['ë™'], x['ì•„íŒŒíŠ¸ëª…'], True)['naver'], axis=1)
                    st.dataframe(df_l_all, column_config=land_config, column_order=["ê³„ì•½ì¼", "ë™", "ì•„íŒŒíŠ¸ëª…", "ë©´ì ", "êµ­í† ë¶€ ì‹¤ê±°ë˜ê°€", "kb_link", "naver_link"], hide_index=True, use_container_width=True)
                else: st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else: st.warning("API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    # 3. ë‰´ìŠ¤ íƒ­
    with t3:
        st.subheader(f"ğŸ“° {region_name} ì£¼ìš” ì†Œì‹")
        
        if not naver_id or not naver_secret:
            st.warning("ì™¼ìª½ ì‚¬ì´ë“œë°”ì— 'ë„¤ì´ë²„ API Key'ë¥¼ ì…ë ¥í•´ì•¼ ë‰´ìŠ¤ê°€ ë³´ì…ë‹ˆë‹¤.")
        else:
            nt1, nt2 = st.tabs(["ğŸ  ë¶€ë™ì‚°", "ğŸ“‘ ì¼ë°˜/í†µí•©"])
            def create_news_tabs(cat_name):
                tabs = st.tabs([p['name'] for p in r_pubs])
                for i, tab in enumerate(tabs):
                    with tab:
                        pub_info = r_pubs[i]
                        items = get_naver_news_list(naver_id, naver_secret, region_name, cat_name, pub_info['name'], pub_info['domain_key'])
                        if items:
                            for n in items:
                                b = '<span class="badge-today">ì˜¤ëŠ˜</span>' if n['is_today'] else ''
                                st.markdown(f'<div class="news-box"><a href="{n["link"]}" target="_blank" class="news-title">{b}{n["title"]}</a><div class="news-meta">{n["source"]} | {n["date_str"]}</div></div>', unsafe_allow_html=True)
                        else: st.info(f"'{pub_info['name']}' ê´€ë ¨ ìµœì‹  ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            with nt1: create_news_tabs("ë¶€ë™ì‚°")
            with nt2: create_news_tabs("ì „ì²´")

with region_tabs[0]: render_region_dashboard("ì¶˜ì²œì‹œ")
with region_tabs[1]: render_region_dashboard("ì›ì£¼ì‹œ")